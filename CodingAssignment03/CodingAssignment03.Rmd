---
title: "Coding Assignment 3"
author: "Team 7"
date: "Due: 2022-12-09 23:59"
output: 
  html_document:
    toc: true
    toc_float: true
---

```{r setup, include=FALSE}
#Put any packages you need here
knitr::opts_chunk$set(echo = TRUE)
library(readxl)
##library(plotly)
library(corrplot)
library(car)
library(gt)
library(gtsummary)


```

A Florida health insurance company wants to predict annual claims for individual clients. The company pulls a random sample of 50 customers. The owner wishes to charge an actuarially fair premium to ensure a normal rate of return. The owner collects all of their current customer’s health care expenses from the last year and compares them with what is known about each customer’s plan. 

The data on the 50 customers in the sample is as follows:

-	Charges: Total medical expenses for a particular insurance plan (in dollars)
-	Age: Age of the primary beneficiary
-	BMI: Primary beneficiary’s body mass index (kg/m2)
-	Female: Primary beneficiary’s birth sex (0 = Male, 1 = Female)
-	Children: Number of children covered by health insurance plan (includes other dependents as well)
-	Smoker: Indicator if primary beneficiary is a smoker (0 = non-smoker, 1 = smoker)
-	Cities: Dummy variables for each city with the default being Sanford

Answer the following questions using complete sentences and attach all output, plots, etc. within this report.


```{r dataset, include=FALSE}
# Bring in the dataset here.
insurancegroup7 <- read_excel("../Data/insurance_0126_Group7.xlsx")
```



## Question 1

Randomly select three observations from the sample and exclude from all modeling (i.e. n=47). Provide the summary statistics (min, max, std, mean, median) of the quantitative variables for the 47 observations.

```{r q1}
set.seed(123456)
index <- sample(seq_len(nrow(insurancegroup7)), size = 3)

#data set of 47 observations ALL columns
training_set <- insurancegroup7[-index,]

#data set of 3 observations ALL columns
testing_set <- insurancegroup7[index,]

# Summary Statistics
summary(training_set[,c(1:3,5)])
noquote("Standard deviation for Charges")
sd(training_set$Charges)
noquote("Standard deviation for Age")
sd(training_set$Age)
noquote("Standard deviation for BMI")
sd(training_set$BMI)
noquote("Standard deviation for Children")
sd(training_set$Children)


```
One thing that is obvious here is that our dependent variable is skewed to the right. The mean is about 5.4 thousand dollars higher than the median and the standard deviation is high, and the range is from 1.1k to 59k. We may have outliers in our data.

## Question 2

Provide the correlation between all quantitative variables

```{r}

corrplot(cor(training_set[,c(1:3,5)]),
         type = "lower",order = "hclust",
         tl.col = "black",
         tl.srt = 45,
         addCoef.col = "black",
         diag = FALSE,)
```
None of the variables have a high correlation with each other.

## Question 3

Run a regression that includes all independent variables in the data table. Does the model above violate any of the Gauss-Markov assumptions? If so, what are they and what is the solution for correcting?
```{r q3 part 1}

model_1 <- lm(Charges~., data = training_set)
summary(training_set)
summary(model_1)

par(mfrow=c(2,2))

##Analyze plot output for assumption violations and provide solutions
##Professor said Residuals vs Fitted violates non-linear
##Normal Q-Q is a violation of #6
plot(model_1)
```
Looking at the residuals vs. fitted plot, there appears to be a violation of Gauss-Markov Assumption #3, specification bias. By using the incorrect functional form “misspecification” occurs, assuming it is a linear function when it’s actually non-linear. The solution is to transform the data using a log function.

Additionally, the Normal QQ plot has a normal flatness, does not form a 45-degree angle, exhibits a heavy tailed distribution, and the dependent variable is not normally distributed. This is a violation of the Gauss-Markov Assumption #6, the error is not normally distributed. The solution is to take the log creating a normal distribution, bringing outliers closer to other charges. (analyze the scatter plots to determine which form is best quadratic or log)

In this example, the first plot titled “Residuals vs. Fitted,” you should not see a true pattern. In this case, since there is a non-linear relationship, you’ve already violated a classical assumption.

The second plot titled “Normal Q-Q” shows the assumption of a normally distributed dependent variable for a fixed set of predictors. If this were a 45-degree line upwards, we could verify this. Unfortunately we do not have it in this case.

The third plot titled “Scale-Location” checks for homoskedasticity. If this assumption were not violated, you’d see random points around a horizontal line. In this case, it is upwards sloping, so you can see there is a “fanning out” effect.

The last plot “Residuals vs. Leverage” keeps an eye out for regression outliers, influential observations, and high leverage points. (Do not worry about this last plot).

Potential Solutions:
1) Quadratic relationship between <independent variable> and Charges
2) Logarithmic relationship between <independent variable> and Charges
3) Dropping variables (dummy variables)

## Question 4

Implement the solutions from question 3, such as data transformation, along with any other changes you wish. Use the sample data and run a new regression. How have the fit measures changed? How have the signs and significance of the coefficients changed?

```{r q4}
par(mfrow=c(2,2))

#base model
model_1 <- lm(Charges~., data = training_set[,c(1:9)])
summary(model_1)
plot(model_1)


#Fix Charges' distribution by using log
training_set$lnCharges <- log(training_set$Charges)
hist(training_set$Charges)
hist(training_set$lnCharges)

training_set$lnAge <- log(training_set$Age)
training_set$AgeSquared <- training_set$Age^2

training_set$BMISquared <-training_set$BMI^2
training_set$lnBMI <- log(training_set$BMI)


#Model of Log of Charges, Age, BMI, Children + dummies
model_lnCharges <- lm(lnCharges~., data = training_set[,c(10,2:9)])
summary(model_lnCharges)
plot(model_lnCharges)


#Model of lnCharges, lnAge, BMI, Children + dummies
model_lnAge <- lm(lnCharges~., data = training_set[,c(10,11,3:9)])
summary(model_lnAge)
plot(model_lnAge)


#Model of lnCharges, Age, Age^2 BMI, Children + dummies
model_AgeSquared <- lm(lnCharges~., data = training_set[,c(10,2:9,12)])
summary(model_AgeSquared)
plot(model_AgeSquared)


#Model of lnCharges, Age, lnBMI, Children + dummies
model_lnBMI <- lm(lnCharges~., data = training_set[,c(10,2,14,3:9)])
summary(model_lnBMI)
plot(model_lnBMI)


#Model of lnCharges, Age, BMI, BMI^2, Children + dummies
model_BMISquared <- lm(lnCharges~., data = training_set[,c(10,2:9,13)])
summary(model_BMISquared)
plot(model_BMISquared)


#Model of lnCharges, lnAge, lnBMI, Children + dummies
model_lnAll <- lm(lnCharges~., data = training_set[,c(10,11,14,4:9)])
summary(model_lnAll)
plot(model_lnAll)
```

## Question 5

#Use the 3 withheld observations and calculate the performance measures for your best two models. Which is the better model? (remember that "better" depends on whether your outlook is short or long run)

```{r q5}
#Danny
testing_set$lnCharges <- log(testing_set$Charges)
testing_set$lnAge <- log(testing_set$Age)
testing_set$AgeSquared <- testing_set$Age^2

testing_set$BMISquared <- testing_set$BMI^2
testing_set$lnBMI <- log(testing_set$BMI)

testing_set$base_model_pred <- predict(model_1, newdata = testing_set) 

testing_set$model_lnAge_pred <- predict(model_lnAge, newdata = testing_set) %>% exp()

testing_set$model_lnBMI_pred <- predict(model_lnBMI, newdata = testing_set) %>% exp()

testing_set$model_AgeSquared_pred <- predict(model_AgeSquared,newdata = testing_set) %>% exp()

testing_set$model_BMISquared_pred <- predict(model_BMISquared,newdata = testing_set) %>% exp()

testing_set$model_lnAll_pred <- predict(model_lnAll,newdata = testing_set) %>% exp()



testing_set$error_bm <- testing_set$base_model_pred - testing_set$Charges

testing_set$error_1 <- testing_set$model_lnAge_pred - testing_set$Charges

testing_set$error_2 <- testing_set$model_lnBMI_pred - testing_set$Charges

testing_set$error_3 <- testing_set$model_AgeSquared_pred - testing_set$Charges

testing_set$error_4 <- testing_set$model_BMISquared_pred - testing_set$Charges

testing_set$error_5 <- testing_set$model_lnAll_pred - testing_set$Charges

# No Transformations
mean(testing_set$error_bm)
# Log of Charges and Log of Age
mean(testing_set$error_1)
#Log of Charges and Log of BMI
mean(testing_set$error_2)
#Log of Charges, Age, Age^2
mean(testing_set$error_3)
#Log of Charges, BMI, BMI^2
mean(testing_set$error_4)
#Log of Charges, Log of Age, Log of BMI
mean(testing_set$error_5)



mae <- function(error_vector){
  error_vector %>% 
  abs() %>% 
  mean()
}

# No Transformations
mae(testing_set$error_bm)
# Log of Charges and Log of Age
mae(testing_set$error_1)
#Log of Charges and Log of BMI
mae(testing_set$error_2)
#Log of Charges, Age, Age^2
mae(testing_set$error_3)
#Log of Charges, BMI, BMI^2
mae(testing_set$error_4)
#Log of Charges, Log of Age, Log of BMI
mae(testing_set$error_5)

rmse <- function(error_vector){
   error_vector^2 %>% 
  mean() %>% 
  sqrt()

}

# No Transformations
rmse(testing_set$error_bm)
# Log of Charges and Log of Age
rmse(testing_set$error_1)
#Log of Charges and Log of BMI
rmse(testing_set$error_2)
#Log of Charges, Age, Age^2
rmse(testing_set$error_3)
#Log of Charges, BMI, BMI^2
rmse(testing_set$error_4)
#Log of Charges, Log of Age, Log of BMI
rmse(testing_set$error_5)



mape <- function(error_vector, actual_vector){
  (error_vector/actual_vector) %>% 
    abs() %>% 
    mean()
}

# No Transformations
mape(testing_set$error_bm, testing_set$Charges)
# Log of Charges and Log of Age
mape(testing_set$error_1, testing_set$Charges)
#Log of Charges and Log of BMI
mape(testing_set$error_2, testing_set$Charges)
#Log of Charges, Age, Age^2
mape(testing_set$error_3, testing_set$Charges)
#Log of Charges, BMI, BMI^2
mape(testing_set$error_4, testing_set$Charges)
#Log of Charges, Log of Age, Log of BMI
mape(testing_set$error_5, testing_set$Charges)

```


## Question 6

Provide interpretations of the coefficients, do the signs make sense? Perform marginal change analysis (thing 2) on the independent variables.

```{r q6}
##Danny
summary(model_1)
summary(model_lnCharges)
summary(model_lnAge)
summary(model_AgeSquared)
summary(model_lnBMI)
summary(model_BMISquared)
summary(model_lnAll)
```

## Question 7


An eager insurance representative comes back with five potential clients. Using the better of the two models selected above, provide the prediction intervals for the five potential clients using the information provided by the insurance rep.

| Customer | Age | BMI | Female | Children | Smoker | City           |
| -------- | --- | --- | ------ | -------- | ------ | -------------- | 
| 1        | 60  | 22  | 1      | 0        | 0      | Oviedo         |
| 2        | 40  | 30  | 0      | 1        | 0      | Sanford        |
| 3        | 25  | 25  | 0      | 0        | 1      | Winter Park    |
| 4        | 33  | 35  | 1      | 2        | 0      | Winter Springs |
| 5        | 45  | 27  | 1      | 3        | 0      | Oviedo         |


```{r q7}
#Janice
```

## Question 8
--Janice
The owner notices that some of the predictions are wider than others, explain why.

## Question 9 
--Kim
Are there any prediction problems that occur with the five potential clients? If so, explain.

