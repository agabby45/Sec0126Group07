---
title: "Coding Assignment 3"
author: "Team 7"
date: "Due: 2022-12-11 23:59"
output: 
  html_document:
    toc: true
    toc_float: true
---

```{r setup, include=FALSE}
#Put any packages you need here
knitr::opts_chunk$set(echo = TRUE)
library(readxl)
##library(plotly)
library(corrplot)
library(car)
library(gt)
library(gtsummary)


```

A Florida health insurance company wants to predict annual claims for individual clients. The company pulls a random sample of 50 customers. The owner wishes to charge an actuarially fair premium to ensure a normal rate of return. The owner collects all of their current customer’s health care expenses from the last year and compares them with what is known about each customer’s plan. 

The data on the 50 customers in the sample is as follows:

-	Charges: Total medical expenses for a particular insurance plan (in dollars)
-	Age: Age of the primary beneficiary
-	BMI: Primary beneficiary’s body mass index (kg/m2)
-	Female: Primary beneficiary’s birth sex (0 = Male, 1 = Female)
-	Children: Number of children covered by health insurance plan (includes other dependents as well)
-	Smoker: Indicator if primary beneficiary is a smoker (0 = non-smoker, 1 = smoker)
-	Cities: Dummy variables for each city with the default being Sanford

Answer the following questions using complete sentences and attach all output, plots, etc. within this report.


```{r dataset, include=FALSE}
# Bring in the dataset here.
insurancegroup7 <- read_excel("../Data/insurance_0126_Group7.xlsx")
```



## Question 1

Randomly select three observations from the sample and exclude from all modeling (i.e. n=47). Provide the summary statistics (min, max, std, mean, median) of the quantitative variables for the 47 observations.

```{r q1}
set.seed(123456)
index <- sample(seq_len(nrow(insurancegroup7)), size = 3)

#data set of 47 observations ALL columns
training_set <- insurancegroup7[-index,]

#data set of 3 observations ALL columns
testing_set <- insurancegroup7[index,]

# Summary Statistics
summary(training_set[,c(1:3,5)])
noquote("Standard deviation for Charges")
sd(training_set$Charges)
noquote("Standard deviation for Age")
sd(training_set$Age)
noquote("Standard deviation for BMI")
sd(training_set$BMI)
noquote("Standard deviation for Children")
sd(training_set$Children)


```
One thing that is obvious here is that our dependent variable is skewed to the right. The mean is about 5.4 thousand dollars higher than the median and the standard deviation is high, and the range is from 1.1k to 59k. We may have outliers in our data.

## Question 2

Provide the correlation between all quantitative variables

```{r}

corrplot(cor(training_set[,c(1:3,5)]),
         type = "lower",order = "hclust",
         tl.col = "black",
         tl.srt = 45,
         addCoef.col = "black",
         diag = FALSE,)
```
None of the variables have a high correlation with each other.

## Question 3

Run a regression that includes all independent variables in the data table. Does the model above violate any of the Gauss-Markov assumptions? If so, what are they and what is the solution for correcting?
```{r q3 part 1}

model_1 <- lm(Charges~., data = training_set)
summary(training_set)
summary(model_1)

par(mfrow=c(2,2))

##Analyze plot output for assumption violations and provide solutions
##Professor said Residuals vs Fitted violates non-linear
##Normal Q-Q is a violation of #6
plot(model_1)
```
Looking at the residuals vs. fitted plot, there appears to be a violation of Gauss-Markov Assumption #3, specification bias. By using the incorrect functional form “misspecification” occurs, assuming it is a linear function when it’s actually non-linear. The solution is to transform the data using a log or quadratic function. 

The Normal QQ plot has a normal flatness, does not form a 45-degree angle, exhibits a heavy tailed distribution, and the dependent variable is not normally distributed. This is a violation of the Gauss-Markov Assumption #6, the error is not normally distributed. A study conducted by Ward et al. found that “health care expenditures are higher for people with excess weight across a wide range of ages and BMI levels, with especially high costs for people with severe obesity.” (Ward et al., 2021) Because it is assumed that the rate of increase in charges related to an increase in BMI is not consistent, one solution is to take the log of charges and the log of BMI creating a normal distribution, bringing outliers closer to other charges. Another solution is to take the log of age, as the rate of increase in charges related to age may not be consistent. We looked at several transformations to determine the best model. 

## Question 4

Implement the solutions from question 3, such as data transformation, along with any other changes you wish. Use the sample data and run a new regression. How have the fit measures changed? How have the signs and significance of the coefficients changed?

```{r q4}
par(mfrow=c(2,2))

#base model
model_1 <- lm(Charges~., data = training_set[,c(1:9)])
summary(model_1)
plot(model_1)


#Fix Charges' distribution by using log
training_set$lnCharges <- log(training_set$Charges)
hist(training_set$Charges)
hist(training_set$lnCharges)

training_set$lnAge <- log(training_set$Age)
training_set$AgeSquared <- training_set$Age^2

training_set$BMISquared <-training_set$BMI^2
training_set$lnBMI <- log(training_set$BMI)


#Model of Log of Charges, Age, BMI, Children + dummies
model_lnCharges <- lm(lnCharges~., data = training_set[,c(10,2:9)])
summary(model_lnCharges)
plot(model_lnCharges)


#Model of lnCharges, lnAge, BMI, Children + dummies
model_lnAge <- lm(lnCharges~., data = training_set[,c(10,11,3:9)])
summary(model_lnAge)
plot(model_lnAge)


#Model of lnCharges, Age, Age^2 BMI, Children + dummies
model_AgeSquared <- lm(lnCharges~., data = training_set[,c(10,2:9,12)])
summary(model_AgeSquared)
plot(model_AgeSquared)


#Model of lnCharges, Age, lnBMI, Children + dummies
model_lnBMI <- lm(lnCharges~., data = training_set[,c(10,2,14,3:9)])
summary(model_lnBMI)
plot(model_lnBMI)


#Model of lnCharges, Age, BMI, BMI^2, Children + dummies
model_BMISquared <- lm(lnCharges~., data = training_set[,c(10,2:9,13)])
summary(model_BMISquared)
plot(model_BMISquared)


#Model of lnCharges, lnAge, lnBMI, Children + dummies
model_lnAll <- lm(lnCharges~., data = training_set[,c(10,11,14,4:9)])
summary(model_lnAll)
plot(model_lnAll)
```
Base Model: Age, BMI, Children, and Smoker all test significant. R2 is 90%, and the residual standard error is 5259. The dummy variables (cities, Female) do not test significant. The variables that tested significant all have a direct relationship with the dependent variable (Charges).

lnCharges Model: By taking the log of Charges, Age, Children, and Smoker all test significant, and BMI no longer tests significant. While you cannot compare transformed models, R2 for this model is 86%. By taking the log of charges, the sign of Winter Park flips to negative. This does not seem logical, as there should be a direct relationship between charges and cities. However, taking the log of charges did make the distribution of charges more normal and the residual standard error is low, 0.4556, meaning the model predicts charges with an error of 0.4506

lnAge Model: By taking the log of Charges and Age, Age, Children, and Smoker test significant, BMI does not test significant. R2 for this model is 86% and Winter Park is negative. The residual standard error is 0.4556. 

AgeSquared: By taking the log of Charges and Age Squared, only Children and Smoker test significant, BMI and Age do not test significant. R2 for this model is 86% and Winter Park and Age Squared are  negative. While the residual standard error is low, the direction of Age Squared and Winter Park does not make sense and several items that logically should test significant do not. 

lnBMI: By taking the log of Charges and Age, Age, Children, BMI, Log BMI, Smoker, and Winter Springs all test significant. BMI changed sign. R2 for this model is 90%. The residual standard error is 0.3948. 

BMISquared: By taking the log of Charges and BMI Squared, Age, Children, BMI, BMI Squared, Smoker, and Winter Springs all test significant. BMI Squared changed sign. R2 for this model is 90%. The residual standard error is 0.3893.

lnAll Model: By taking the log of Charges, Age, BMI, the fit reduced to 86% and the standard error increased to .451. Only lnAge, Children, Smoker tested significantly. Winterpark changed to a negative coefficient.

## Question 5

#Use the 3 withheld observations and calculate the performance measures for your best two models. Which is the better model? (remember that "better" depends on whether your outlook is short or long run)

```{r q5}
#Danny
testing_set$lnCharges <- log(testing_set$Charges)
testing_set$lnAge <- log(testing_set$Age)
testing_set$AgeSquared <- testing_set$Age^2

testing_set$BMISquared <- testing_set$BMI^2
testing_set$lnBMI <- log(testing_set$BMI)

testing_set$base_model_pred <- predict(model_1, newdata = testing_set) 

testing_set$model_lnAge_pred <- predict(model_lnAge, newdata = testing_set) %>% exp()

testing_set$model_lnBMI_pred <- predict(model_lnBMI, newdata = testing_set) %>% exp()

testing_set$model_AgeSquared_pred <- predict(model_AgeSquared,newdata = testing_set) %>% exp()

testing_set$model_BMISquared_pred <- predict(model_BMISquared,newdata = testing_set) %>% exp()

testing_set$model_lnAll_pred <- predict(model_lnAll,newdata = testing_set) %>% exp()



testing_set$error_bm <- testing_set$base_model_pred - testing_set$Charges

testing_set$error_1 <- testing_set$model_lnAge_pred - testing_set$Charges

testing_set$error_2 <- testing_set$model_lnBMI_pred - testing_set$Charges

testing_set$error_3 <- testing_set$model_AgeSquared_pred - testing_set$Charges

testing_set$error_4 <- testing_set$model_BMISquared_pred - testing_set$Charges

testing_set$error_5 <- testing_set$model_lnAll_pred - testing_set$Charges

# No Transformations
mean(testing_set$error_bm)
# Log of Charges and Log of Age
mean(testing_set$error_1)
#Log of Charges and Log of BMI
mean(testing_set$error_2)
#Log of Charges, Age, Age^2
mean(testing_set$error_3)
#Log of Charges, BMI, BMI^2
mean(testing_set$error_4)
#Log of Charges, Log of Age, Log of BMI
mean(testing_set$error_5)



mae <- function(error_vector){
  error_vector %>% 
  abs() %>% 
  mean()
}

# No Transformations
mae(testing_set$error_bm)
# Log of Charges and Log of Age
mae(testing_set$error_1)
#Log of Charges and Log of BMI
mae(testing_set$error_2)
#Log of Charges, Age, Age^2
mae(testing_set$error_3)
#Log of Charges, BMI, BMI^2
mae(testing_set$error_4)
#Log of Charges, Log of Age, Log of BMI
mae(testing_set$error_5)

rmse <- function(error_vector){
   error_vector^2 %>% 
  mean() %>% 
  sqrt()

}

# No Transformations
rmse(testing_set$error_bm)
# Log of Charges and Log of Age
rmse(testing_set$error_1)
#Log of Charges and Log of BMI
rmse(testing_set$error_2)
#Log of Charges, Age, Age^2
rmse(testing_set$error_3)
#Log of Charges, BMI, BMI^2
rmse(testing_set$error_4)
#Log of Charges, Log of Age, Log of BMI
rmse(testing_set$error_5)



mape <- function(error_vector, actual_vector){
  (error_vector/actual_vector) %>% 
    abs() %>% 
    mean()
}

# No Transformations
mape(testing_set$error_bm, testing_set$Charges)
# Log of Charges and Log of Age
mape(testing_set$error_1, testing_set$Charges)
#Log of Charges and Log of BMI
mape(testing_set$error_2, testing_set$Charges)
#Log of Charges, Age, Age^2
mape(testing_set$error_3, testing_set$Charges)
#Log of Charges, BMI, BMI^2
mape(testing_set$error_4, testing_set$Charges)
#Log of Charges, Log of Age, Log of BMI
mape(testing_set$error_5, testing_set$Charges)

```
After care full studying the BIAS, MAE, RMSE, and MAPE, we have concluded that the best fit model is the base model. With a 90% fit model and the smallest BIAS, MAE, RMSE, and MAPE, out of all the models, the base model will give us the best results. 
To better protect the model against large forecasting errors, we looked at the RMSE, and our model scored better on the RMSE than any of the other models. This means that whether its long run or short run, our base model will be a better model than any of the other models.



## Question 6

Provide interpretations of the coefficients, do the signs make sense? Perform marginal change analysis (thing 2) on the independent variables.

```{r q6}
model_1 <- lm(Charges~., data = training_set[,c(1:9)])
summary(model_1)

```

After reviewing the coefficients, the coefficient signs for Age, BMI, and Children (tested significant) are correct since they have a direct relationship with the dependent variable (Charges).

We expected Female (did not test significant) to be positive and also has a direct relationship with Charges because, on average, there are more potential medical costs with being a female. For example: Getting pregnant and having a child.

Smoker should have a positive coefficient because being a smoker will only increase medical costs. 

Age- for each year that goes by, there will be a $246 increase approximately in total charges. MOE=121.74
BMI- For every point increase in BMI, there will be a $410 increase approximately in total charges. MOE=369.7
Female- MOE=3,902.78
Children- For each child there will be approximately $1,296 increase in total charges. MOE=1,186.24
Smoker- A smoker can expect to have approximately $29,982 more in total charges than a non smoker. MOE=4,006
Winter Springs- MOE=4,774.04
Winter Park- MOE=5,666.24
Oviedo- MOE=4,921.08

Cities (WinterSprings, WinterPark, Oviedo): None of the city variables tested significantly; however, living in WinterSprings or WinterPark or Oviedo will cost on average $4,155, $1,140, and $1,063 more than living in Sanford.



## Question 7


An eager insurance representative comes back with five potential clients. Using the better of the two models selected above, provide the prediction intervals for the five potential clients using the information provided by the insurance rep.

| Customer | Age | BMI | Female | Children | Smoker | City           |
| -------- | --- | --- | ------ | -------- | ------ | -------------- | 
| 1        | 60  | 22  | 1      | 0        | 0      | Oviedo         |
| 2        | 40  | 30  | 0      | 1        | 0      | Sanford        |
| 3        | 25  | 25  | 0      | 0        | 1      | Winter Park    |
| 4        | 33  | 35  | 1      | 2        | 0      | Winter Springs |
| 5        | 45  | 27  | 1      | 3        | 0      | Oviedo         |


```{r q7}
Customer_1 <- data.frame(Age = 60, BMI = 22, Children = 0, Female = 1, Smoker = 0, WinterSprings = 0, WinterPark = 0, Oviedo = 1)
Customer_2 <- data.frame(Age = 40, BMI = 30, Children = 1, Female = 0, Smoker = 0, WinterSprings = 0, WinterPark = 0, Oviedo = 0)
Customer_3 <- data.frame(Age = 25, BMI = 25, Children = 0, Female = 0, Smoker = 1, WinterSprings = 0, WinterPark = 1, Oviedo = 0)
Customer_4 <- data.frame(Age = 33, BMI = 35, Children = 2, Female = 1, Smoker = 0, WinterSprings = 1, WinterPark = 0, Oviedo = 1)
Customer_5 <- data.frame(Age = 45, BMI = 27, Children = 3, Female = 1, Smoker = 0, WinterSprings = 0, WinterPark = 0, Oviedo = 1)


predict(model_1, newdata= Customer_1, interval = "prediction")
predict(model_1, newdata= Customer_2, interval = "prediction")
predict(model_1, newdata= Customer_3, interval = "prediction")
predict(model_1, newdata= Customer_4, interval = "prediction")
predict(model_1, newdata= Customer_5, interval = "prediction")

```
For Customer 1 we expect the charges to be $8,600 give or take $12,000 but obviously not lower than $0
For Customer 2 we expect the charges to be $5,500 give or take $11,000 but obviously not lower than $0.
For Customer 3 we expect the charges to be $30,000 give or take $12,500.
For Customer 4 we expect the charges to be $14,000 give or take $12,500.
For Customer 5 we expect the charges to be $12,000 give or take $12,000 but obviously not lower than $0.

## Question 8

The owner notices that some of the predictions are wider than others, explain why.

The training set only has 47 observations which causes larger forecasting errors. Additionally, there is some conditional variables (BMI, city) that adds to error size and will be captured in the wide prediction interval. With our model, customer 3 was a male smoker and customer 4 is a female with 2 children. Both of these customers had a range of about $25,000 that can be explained by being a smoker or having multiple children. 

## Question 9 
Are there any prediction problems that occur with the five potential clients? If so, explain.

The ranges showed extrapolation for our Charges range. Model_1 (default model with no transformations) shows Charges has a range of 1,147 to 58,571. The minimum value was breached with Customers 1, 2, and 5. This could be because of the low number of observations (N=47) causing the forecast model to have large errors.
